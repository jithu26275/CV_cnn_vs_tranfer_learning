{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fc313f57",
      "metadata": {
        "id": "fc313f57"
      },
      "source": [
        "# Cnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "a7863af2",
      "metadata": {
        "id": "a7863af2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import  cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout ,Rescaling\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from collections import Counter\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# import function_cnn\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "# y_test_cat = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "2ad8a5b7",
      "metadata": {
        "id": "2ad8a5b7"
      },
      "outputs": [],
      "source": [
        "# Convert labels to one-hot vectors\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Create a preprocessing layer for normalization\n",
        "normalization_layer = Rescaling(1./255)\n",
        "X_train = normalization_layer(X_train)\n",
        "X_test = normalization_layer(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "85f4c49f",
      "metadata": {
        "id": "85f4c49f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7220a29f",
      "metadata": {
        "id": "7220a29f"
      },
      "outputs": [],
      "source": [
        "# Load saved model\n",
        "model = load_model(\"../CNN_models_final/SGD_aug_morlyrs.keras\")\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test,y_test_cat)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Test Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87b28ff4",
      "metadata": {
        "id": "87b28ff4"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(X_train,y_train_cat)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Test Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14e6c84e",
      "metadata": {
        "id": "14e6c84e"
      },
      "source": [
        "# Mobilenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "a5f9200a",
      "metadata": {
        "id": "a5f9200a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "25777e65",
      "metadata": {
        "id": "25777e65"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import  cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "fa032340",
      "metadata": {
        "id": "fa032340"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "778da267",
      "metadata": {
        "id": "778da267"
      },
      "outputs": [],
      "source": [
        "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\",\t\"ship\",\t\"truck\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "d0ab1259",
      "metadata": {
        "id": "d0ab1259"
      },
      "outputs": [],
      "source": [
        "Img_size = 224\n",
        "Batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "2f5e03c6",
      "metadata": {
        "id": "2f5e03c6"
      },
      "outputs": [],
      "source": [
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "# Define resize size (e.g. 224 for MobileNetV2)\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16  # adjust based on your GPU RAM\n",
        "\n",
        "# Create tf.data datasets\n",
        "X_train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train_cat))\n",
        "X_test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test_cat))\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))  # resize to (224,224)\n",
        "    image = preprocess_input(image)                       # MobileNetV2 preprocess\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing + batching + prefetching\n",
        "X_train_ds = X_train_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "X_test_ds  = X_test_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "72054067",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "3fd3c264",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_model(\"mobnet_base_s_full.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "84af8467",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"SGD\", loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "5e47dd4d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 290ms/step - accuracy: 0.8599 - loss: 0.4067\n",
            "Test Accuracy: 0.8599, Test Loss: 0.4067\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(X_test_ds)\n",
        "print(f\"Test Accuracy: {acc:.4f}, Test Loss: {loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "211e9af4",
      "metadata": {
        "id": "211e9af4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5141ef64",
      "metadata": {
        "id": "5141ef64"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "# Rebuild clean model with same architecture\n",
        "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(224,224,3)),\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Load weights instead of broken model\n",
        "model.load_weights(\"mobnetfintune_s.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65411251",
      "metadata": {
        "id": "65411251"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "# Re-compile the model before evaluation\n",
        "model.compile(\n",
        "    optimizer= SGD(),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Now evaluate\n",
        "loss, acc = model.evaluate(X_test_ds)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Test Loss: {loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31033095",
      "metadata": {
        "id": "31033095"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(X_train_ds)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Test Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BDMBEH-Z1Ode",
      "metadata": {
        "id": "BDMBEH-Z1Ode"
      },
      "source": [
        "Densenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rFP1v8es1Qae",
      "metadata": {
        "id": "rFP1v8es1Qae"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "# Rebuild clean model with same architecture\n",
        "base_model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
        "base_model.trainable = False   # or True if you fine-tuned (not needed for evaluation)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(224,224,3)),\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')   # adjust classes if needed\n",
        "])\n",
        "\n",
        "# Load weights from your trained model\n",
        "model.load_weights(\"densenet_a_bm.keras\")\n",
        "\n",
        "# Compile before evaluation\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Evaluate on test dataset\n",
        "loss, acc = model.evaluate(X_test_ds)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Test Loss: {loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sZQbRhwn28Wk",
      "metadata": {
        "id": "sZQbRhwn28Wk"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(X_train_ds)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Test Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1VefMCjq3BSF",
      "metadata": {
        "id": "1VefMCjq3BSF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "upbjop553sUK",
      "metadata": {
        "id": "upbjop553sUK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import  cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NfshV03m3t_M",
      "metadata": {
        "id": "NfshV03m3t_M"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\",\t\"ship\",\t\"truck\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vblpzAoi4NN1",
      "metadata": {
        "id": "vblpzAoi4NN1"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(X_test_ds)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Test Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hP89koAV4XTf",
      "metadata": {
        "id": "hP89koAV4XTf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7XJ3OjGc4dpK",
      "metadata": {
        "id": "7XJ3OjGc4dpK"
      },
      "outputs": [],
      "source": [
        "model = load_model(\"effnet_a_B4.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LUKZ-ovD5GuY",
      "metadata": {
        "id": "LUKZ-ovD5GuY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as effnet_preprocess\n",
        "from tensorflow.keras import layers, models, optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nOluZmua46Qk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOluZmua46Qk",
        "outputId": "2c3a75f0-8d13-4bb8-a210-12168580ad9f"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 380\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "# EfficientNetB4 preprocessing\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "X_test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test_cat))\n",
        "X_test_ds = X_test_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Load trained weights\n",
        "model.load_weights(\"effnet_a_B4.keras\")\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test_ds)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Test Loss: {loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tHjetVmO40BC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tHjetVmO40BC",
        "outputId": "7c64ba2e-3c3c-44d0-b84f-83a8f90483ae"
      },
      "outputs": [],
      "source": [
        "# Example for EfficientNetB4\n",
        "IMG_SIZE = 380\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = preprocess_input(image)\n",
        "    return image, label\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train_cat))\n",
        "train_ds = train_ds.map(preprocess).batch(16).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "model.load_weights(\"effnet_a_B4.keras\")\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(train_ds)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kh18bb8_44AO",
      "metadata": {
        "id": "kh18bb8_44AO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat  = to_categorical(y_test, 10)\n",
        "\n",
        "# Define EfficientNetB5 image size and batch size\n",
        "IMG_SIZE = 456\n",
        "BATCH_SIZE = 16  # Adjust depending on your GPU\n",
        "\n",
        "# Create tf.data datasets\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train_cat))\n",
        "test_ds  = tf.data.Dataset.from_tensor_slices((X_test, y_test_cat))\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))  # Resize to 456x456\n",
        "    image = preprocess_input(image)                       # EfficientNet preprocessing\n",
        "    return image, label\n",
        "\n",
        "# Apply preprocessing + batching + prefetching\n",
        "train_ds = train_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_ds  = test_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AczcIEcd60tA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AczcIEcd60tA",
        "outputId": "5f9ba3f0-2f20-4142-ad02-2390a5c55b40"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"effnet_a_B5.keras\")\n",
        "loss, acc = model.evaluate(test_ds)\n",
        "print(f\"Test Accuracy: {acc:.4f}, Test Loss: {loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P1ld62tZ7h0C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1ld62tZ7h0C",
        "outputId": "b53b24fd-2e11-4c8f-b351-80ca71b88e9b"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(train_ds)\n",
        "print(f\"Test Accuracy: {acc:.4f}, Test Loss: {loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e2pwu4q78s5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2pwu4q78s5",
        "outputId": "231d12a4-e997-4afc-ca4c-066d57131f05"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.applications import EfficientNetB4, EfficientNetB5\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# --- Settings ---\n",
        "MODEL_PATH = \"effnet_a_B4.keras\"  # change for B5 if needed\n",
        "IMG_SIZE = 380   # 380 for B4, 456 for B5\n",
        "BATCH_SIZE = 16\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# --- Prepare labels ---\n",
        "y_train_cat = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test_cat  = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "# --- Preprocessing function ---\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image = preprocess_input(image)  # EfficientNet preprocess\n",
        "    return image, label\n",
        "\n",
        "# --- Prepare datasets ---\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train_cat))\n",
        "train_ds = train_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test_cat))\n",
        "test_ds = test_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# --- Rebuild model architecture ---\n",
        "base_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "# --- Load weights ---\n",
        "model.load_weights(MODEL_PATH)\n",
        "\n",
        "# --- Compile for evaluation ---\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# --- Evaluate ---\n",
        "train_loss, train_acc = model.evaluate(train_ds)\n",
        "test_loss, test_acc   = model.evaluate(test_ds)\n",
        "\n",
        "print(f\"Train Accuracy: {train_acc:.4f}, Train Loss: {train_loss:.4f}\")\n",
        "print(f\"Test  Accuracy: {test_acc:.4f}, Test  Loss: {test_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "571be18f",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
